\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[breaklinks=true,bookmarks=false]{hyperref}

\cvprfinalcopy % *** Uncomment this line for the final submission

\def\cvprPaperID{****} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
%\ifcvprfinal\pagestyle{empty}\fi
\setcounter{page}{4321}
\begin{document}

%%%%%%%%% TITLE
\title{WhatsApp Chat Summarization}

\author{Andrea Auletta\\
{\tt\small andrea.auletta@studenti.unipd.it}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
\and
Davide Baggio\\
{\tt\small davide.baggio.1@studenti.unipd.it}
\and
Marco Bernardi\\
{\tt\small marco.bernardi.11@studenti.unipd.it}
\and
Marco Brigo\\
{\tt\small marco.brigo@studenti.unipd.it}
\and
Sebastiano Sanson\\
{\tt\small sebastiano.sanson@studenti.unipd.it}
}

\maketitle
%\thispagestyle{empty}

%%%%%%%%% ABSTRACT
\begin{abstract}This research project in Natural Language Processing (NLP) 
   focuses on the development of an automated system for the summarization 
   of chat messages, applicable to both group and individual conversations. The objective is to generate concise summaries of conversations, 
   thereby obviating the need for users to review all messages individually. 
   This application is especially pertinent in contexts where chat logs proliferate quickly, 
   offering significant benefits in terms of time savings and cognitive load reduction for users.
\end{abstract}

%%%%%%%%% BODY TEXT
\section{Introduction}

In the era of digital communication, chat platforms have become fundamentals in our daily interactions, whether they are personal or professional. This new type of transmission favors real-time messages exchange which allows users to engage in conversations that can quickly accumulate extensive chat logs. The huge volume of messages, especially in active group chats formed by dozens if not hundreds of users, often makes it difficult for users to stay updated without dedicating substantial time to review each message. This challenge highlights the need for an efficient method that enables users to quickly extract essential information from chat conversations.

This research project addresses this need by developing an automated system for summarizing chat messages with the goal to generate concise summaries, reducing the need to sort through all messages. By doing so, users can quickly obtain the main points of discussions, significantly saving time and reducing cognitive load.

The significance of this application is evident in various contexts: for instance, in corporate environments, project teams often heavily rely on group chats to coordinate tasks, share updates and exchange miscellaneous informations; similarly, social groups frequently engage in dynamic conversations. In both scenarios, an automated summarization system can enhance productivity and ensure important information is not overlooked.

This research aims to explore and implement state of the art NLP techniques to create an effective summarization system, focusing on the datasets used, the manipulation of them in order to obtain always a coherent data structure, how we obtained new examples to test the performances and the results we got after all.

TO DO: overview of our main results!

\section{Datasets}

In this section, we explore datasets essential for training and evaluating automated summarization systems for chat messages: an ideal dataset should have a variety of conversation styles and contexts to ensure the robustness and versatility of the summarization models. The datasets should contain real-life or realistic dialogues annotated with concise and accurate summaries. Additionally, the data should reflect diverse communication patterns, including informal and formal registers, and incorporate common conversational elements such as slang, emojis, eventual typos, the use of voice messages and images. We present below two notable datasets, SAMSum and DialogSum (both obtained by Hugging Face repository), which fulfill these criteria and provide rich resources for advancing the field of conversational AI.

\subsection{SAMSum}

The SAMSum~\cite{DBLP:journals/corr/abs-1911-12237} dataset contains about 16,000 messenger-like conversations with summaries splitted in:
\begin{itemize}
    \item training: 14,732;
    \item validation: 818;
    \item test: 819.
\end{itemize}
Conversations were created and written down by linguists fluent in English. 
Linguists were asked to create conversations similar to those they write on a daily basis, reflecting the proportion of topics of their real-life messenger convesations. 
The style and register are diversified - conversations could be informal, semi-formal or formal, 
they may contain slang words, emoticons and typos. Then, the conversations were annotated with summaries. 
It was assumed that summaries should be a concise brief of what people talked about in the conversation in third person. 
The SAMSum dataset was prepared by Samsung R\&D Institute Poland and is distributed for research purposes.

\subsection{Dialogsum}

DialogSum~\cite{chen-etal-2021-dialogsum} is an extensive dialogue summarization dataset comprising 13,460 dialogues splitted in: 
\begin{itemize}
    \item training: 12,460;
    \item validation: 500;
    \item test: 1,500.
\end{itemize}
supplemented by an additional 100 holdout dialogues designated for topic generation, which contain the id, dialogue, and topic fields. 
Each dialogue is paired with manually annotated summaries and topics. The dataset is exclusively in English and includes four data fields: the text of the dialogue, a human-written summary of the dialogue, a human-written topic or one-liner of the dialogue, and a unique identifier for each example. 

DialogSum distinguishes itself from previous datasets by incorporating dialogues under rich real-life scenarios, including a wider array of task-oriented contexts. 
The dialogues exhibit clear communication patterns and intents, making them suitable for summarization.

\subsection{Custom Dataset}

In order to obtain a dataset with an increased volume of data, a broader spectrum of conversation scenarios and an enhanced evaluation, we decided to concatenate the previously mentioned datasets into a bigger one. \\
The splits of the new dataset are as follows:
\begin{itemize}
    \item training: 27,192;
    \item validation: 1,318;
    \item test: 2,319.
\end{itemize}

To obtain it we had to preprocess the Dialogsum dataset and... TO DO
% dialogsum tolta una colonna topic

\section{Models Involved}

\subsection{BART}

TO DO

\subsection{Florence-2 Large}

To ensure that the images were also processed by the summarization model we had to find a way for converting them into a detailed description of their content. For this specific task we used Florence-2 [TO DO: CITE https://arxiv.org/abs/2311.06242] by Microsoft, which is an advanced vision foundation model that uses a prompt-based approach to handle a wide range of vision and vision-language tasks. It was designed to take text-prompt as task instructions and generate desirable results in text forms, whether it be captioning, object detection, grounding or segmentation. This model leverages on the FLD-5B dataset, containing 5.4 billion annotations across 126 million images, to master multi-task learning. The model's sequence-to-sequence architecture enables it to excel in both zero-shot and fine-tuned settings, proving to be a competitive vision foundation model.


\subsection{Whisper}

As for the images, we had also to convert the voice messages to text only. To do this task we used Whisper by OpenAI [TO DO: CITE https://cdn.openai.com/papers/whisper.pdf], an automatic speech recognition (ASR) system trained on 680,000 hours of multilingual and multitask supervised data collected from the web. The use of such a large and diverse dataset lead to improved robustness to accents, background noise and technical language, which is really helpful in our use case scenario since most of the times the voice messages are not in top notch quality. Moreover, it enables transcription in multiple languages, as well as translation from those languages into English.

\section{Fine Tuning}

\section{Testing}

\section{Results}


%\subsection{Suggested Structure}

%The following is a suggested structure for your report:

%\begin{itemize}
%	\item Introduction (20\%): describe the problem you are working on, why it's important, what are your goals, and provide also an overview of your main results.
%	\item Dataset (20\%): describe the data you are working with for your project. What type of data is it? Where did it come from? How much data are you working with? Did you have to do any preprocessing, filtering, etc., and why?
%	\item Method (30\%): discuss your approach for solving the problems that you set up in the introduction. Why is your approach the right thing to do? Did you consider alternative approaches? It may be helpful to include figures, diagrams, or tables to describe your method or compare it with others.
%	\item Experiments (30\%): discuss the experiments that you performed. The exact experiments will vary depending on the project, but you might compare with prior work, perform an ablation study to determine the impact of various components of your system, experiment with different hyperparameters or architectural choices. You should include graphs, tables, or other figures to illustrate your experimental results.
%\end{itemize}	

%-------------------------------------------------------------------------
{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

\end{document}
